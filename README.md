# Local Memory MCP Server üß†

A lightweight, privacy-first, "Zero-Docker" memory server for AI agents. This server provides semantic search, keyword search, and a knowledge graph‚Äîall running natively on your local machine.

## Key Features

-   **Hybrid Search**: Semantic (Vector) search + Keyword (FTS5) search.
-   **Local Embeddings**: Uses `transformers.js` (ONNX) to run `all-MiniLM-L6-v2` locally on your CPU.
-   **Knowledge Graph**: Structured `entities` and `relations` tables to link facts.
-   **The Archivist**: Configurable "Auto-Ingestion" strategies for automatic graph building.
-   **Privacy-First**: Zero data leaves your machine. No mandatory cloud APIs.
-   **Resource Efficient**: ~50MB - 200MB RAM usage. 

## üåê Cross-Agent Shared Context

A core advantage of this server is its ability to serve as a **centralized long-term memory pool** for all your AI workflows. 

Unlike standard agent memories that are ephemeral or locked to a single session, this server allows multiple MCP-enabled agents (e.g., Claude Desktop, IDE extensions, or custom CLIs) to:
- **Share Knowledge**: Information learned by one agent is instantly accessible to another.
- **Maintain Consistency**: Ensure all your AI tools operate from the same established facts and entity history.
- **Persistent Intelligence**: Your interaction history matures over time into a robust, structured knowledge base available across your entire local ecosystem.

---

## üõ† Installation

### 1. Prerequisites
-   **Node.js**: v18 or higher.
-   **Build Tools**: Python and C++ build tools (required by `better-sqlite3` native compilation).

### 2. Setup
```bash
git clone https://github.com/Beledarian/mcp-local-memory.git
cd mcp-local-memory
npm install
npm run build
```

---

## ‚öôÔ∏è Configuration

Control the server behavior via environment variables:

| Variable | Options | Default | Description |
| :--- | :--- | :--- | :--- |
| `ARCHIVIST_STRATEGY` | `passive`, `nlp`, `llm` | `passive` | Control the auto-ingestion behavior. |
| `OLLAMA_URL` | URL string | `http://localhost:11434` | Endpoint for the LLM strategy. |

### Archivist Strategies
1.  **`passive`**: The server does nothing automatically. It waits for the Agent to call graph tools.
2.  **`nlp`**: Automatically extracts People, Places, and Organizations from every memory using the `compromise` library.
3.  **`llm`**: Sends new memories to a local LLM (Ollama) to perform high-quality entity and relation extraction.

---

## üîß Tools for Agents

The server exposes the following MCP tools:

### Memory Management
-   **`remember_fact(text, tags?)`**: Saves a new piece of information.
-   **`recall(query, limit?)`**: Search for relevant past entries via Vector or FTS search.
-   **`list_recent_memories(limit?)`**: View the latest context.
-   **`forget(memory_id)`**: Delete a specific entry.
-   **`export_memories(path)`**: Backup all data to a JSON file.

### Knowledge Graph
-   **`create_entity(name, type, observations?)`**: Manually define an entity.
-   **`create_relation(source, target, relation)`**: Link two entities with a predicate.
-   **`read_graph(center?, depth?)`**: Explore the network of linked facts.

---

## üèó System Architecture

The heart of the system is a single `memory.db` SQLite file. 

1.  **Semantic Layer**: `sqlite-vec` extension stores 384-dimensional embeddings generated by `transformers.js`.
2.  **Text Layer**: SQLite FTS5 index kept in sync via database triggers.
3.  **Graph Layer**: Relational tables with foreign key constraints to ensure data integrity.

---

## üß™ Testing

Run internal verification tests:
-   `npx tsx test_verification.ts` (Core flow)
-   `npx tsx test_embedding.ts` (AI Model check)
-   `npx tsx test_graph.ts` (Graph check)
-   `npx tsx test_archivist_nlp.ts` (Auto-ingestion check)

## License
MIT

